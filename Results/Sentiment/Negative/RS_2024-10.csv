1ftdxjx,1,2024-09-30,Iâ€™m done ðŸ˜­ðŸ˜­,u/Zealousideal_Mud7766,venting,https://www.reddit.com/r/venting/comments/1ftdxjx/im_done/,"Iâ€™m a college student and I feel frustrated with college. Iâ€™m in community college and I had to turn in a paper to my critical thinking class and I used a rewording software program to reword what I had so I could meet the requirement that was needed for the paper and the teacher used turn it in and heâ€™s telling me that I cheated when all I did was reword my original paper to met a requirement. Itâ€™s just so frustrating when I use a wording program. I am the villain but Iâ€™ve seen people that I have classes with plagiarize papers use ChatGPT to do their papers and somehow I am the one in the wrong. I get that itâ€™s  wrong to plagiarize and do this on papers but people do it to get by. Iâ€™m not saying itâ€™s OK but I just feel that. I spend all this money and all this effort time. Writing papers and doing work and end up failing the class and it just feels defeating and pointless and when you try to talk to the teachers about it and plead your case it seems like they donâ€™t care they have their own set of opinions. 
",User_deleted,1
1fu8xe4,1,2024-10-02,School accused me of using AI for essay,u/JustExam1206,Advice,https://www.reddit.com/r/Advice/comments/1fu8xe4/school_accused_me_of_using_ai_for_essay/,"Hello, I'm a senior in highschool and have just been told in the first time in my life that they believe I used AI to write my essay in my AP Lit class. They said this was because of two things, their AI detector said my essay was 99.8% AI generated and that two, since majority of it was pasted onto the document it clearly wasn't written. I tried explaining to them that if you ask either any of my old english teachers or my friends they'll tell you I write like a psycho. 

I like using a lot of documents for different parts of my essay and then pasting them all together and fixing them. I know this makes me sound crazy but its what I found to work best for me. Issue is I deleted all these documents for space, which I understand makes me seem hella suspicious. 

I also told the admin I sometimes used grammarly for help as well as maybe chatgpt to check my thesis or if I'm using a word correctly but that's about it. I'm scared this could potentially ruin my  chances for scholarships and other opportunities for college. 

The teacher has a known history of never giving out a grade higher than a 90, and is rude to the whole student body. The admin know I have a CAP plan (a private catholic school thing) and can't be talked to about these things without an adult, which the school broke. I have nothing to prove my innocence and it feels like a loosing battle. 

Any advice? ",active,0
1futw7o,1,2024-10-02,What's with this sub's perception of Honor & Integrity?,u/lovingpersona,Teachers,https://www.reddit.com/r/Teachers/comments/1futw7o/whats_with_this_subs_perception_of_honor_integrity/,"I've recently scrolled through the sub to see people's takes on ever growing pandemic that is chatgpt cheating. In the comments section a lot of people showed their view points, and why they deter students from cheating. A lot of common ones like ""at some point all that information you skipped out on will catch up to you"" or ""school is a place where you are allowed and suppose to make mistakes, and therefore learn, you won't have same opportunity in the job market"". However, one of those was a rather popular take, yet in my opinion most laughable one: ""Cheating hurts student's honor & integrity"".

Personally, I am against cheating. Since if it was allowed mainstream, the people's natural laziness would take over and they'd just cheat their way to all the high paying jobs without putting in the effort of actually processing the hard rough knowledge that makes those positions so high paying (because few can get in). Which in turn would result in a society with underqualified doctors, lawyers, and etc.

However, saying that cheating lowers student morality in this harsh brutal world where everyone fights for survival, is just hilarious. Nobody in real life plays fair. Sure, we might criticize students for having chatpgpt write their essays for them, yet in real world script writers and comic artists are now adopting this technology to pump out their product faster, in turn earning more money. Journals, magazines and news websites actively avoid giving citations to the big claims they usually make. Big tech actively plagiarizes stuff, the only difference between them and a student is that they have thousands of suitcase men ready to jump and devastate any lawsuit about to be thrown at them. Even if we lower down our view to everyday people, backstabbing and gossiping is extremely prominent. If people can, they WILL throw you under the bus. I've even seen this occur in schools, which is ironic considering it's the place that is suppose to teach you about values of Honor & Integrity.

It is no wonder that when somebody tells them that ""you're breaking the honor code"", students care less, because they know that it doesn't matter in real life. Heck, they don't even need to know, they can see it for themselves. All that truly matters is how good are you're at winning, not how fair you're at it.",User_deleted,0
1fuxia0,1,2024-10-02,Professors - are all of you seeing an increase in cheating? ,u/smallgrayrock,AskProfessors,https://www.reddit.com/r/AskProfessors/comments/1fuxia0/professors_are_all_of_you_seeing_an_increase_in/,"Hey Profs, I want your insight. 

I'm dating a professor who teaches online courses, and every day he tells me about the overwhelming amount of students using ChatGPT to cheat on assignments. It's gotten to the point where he's questioning the future of education because it feels like he's just teaching robots instead of real people. Each time he uncovers one instance of cheating..he looks back and realizes that its constant for the student and this is happening over and over. He's frustrated and disheartened, and I can't help but wonderâ€”are other professors seeing this too?  How big of an issue is this becoming in your experience, and what do you think can be done about it?  I want to reassure him but if this is happening everywhere, not sure what to say. ",User_deleted,2
1fvrzhe,6,2024-10-04,Has anyone tried a rubric like this to counter AI use?,u/Adventurekitty74,Professors,https://www.reddit.com/r/Professors/comments/1fvrzhe/has_anyone_tried_a_rubric_like_this_to_counter_ai/,"My institution says if you dock a student points for cheating you have to file an academic misconduct report. This system works okay when you have a handful of cases. 

Sure the report is an online form, easy enough, but you also need to meet with the student individually and that takes a lot of time if itâ€™s more than a few. If the student appeals you have to present to a committee designed to fail because the burden of proof is on the professor.

I have situations now where I have 50 or 100 students who are cheating weekly on coded projects. A few cases are classic plagiarism - copied anotherâ€™s work - but now we also have misused ChatGPT and copied another students GPTâ€™d code. We say in the syllabus and often in-class donâ€™t use it because this is a foundations course. Itâ€™s running with scissors for you. 

Considering making the rubric on all future assignments maybe 50 points for convincing me through your use of problem solving and code that does not misuse AI/online resources. Then 50 percent for everything else. If itâ€™s part of the rubric surely I can dock points if my checks flag the code? Would still submit academic misconduct forms for egregious cases. Students who want to argue their grade still could too, but then the burden of proof is on them and I can go back to being a teacher instead of this awful either punish everyone or no one choice currently in place. 

The issue to reiterate is that current policies were not designed for AI use and there is no middle ground more reasonable to manage available policy wise.

Think it might work? 
",active,7
1fxwb82,24,2024-10-06,Need Help with IM Pimping and a Horrible Preceptor,u/okmaxd,medicalschool,https://www.reddit.com/r/medicalschool/comments/1fxwb82/need_help_with_im_pimping_and_a_horrible_preceptor/,"Hey guys,

So I got two more weeks of my IM rotation with this awful preceptor. She makes me round on patients on my own and doesnâ€™t show up until the end of the day. Then, I present my patients and then itâ€™s just her pimping me while munching on her food in the cafeteria as I present. But thatâ€™s not the purpose of this post although I think she should not be a preceptor.

Her expectations from a third-year medical student on his first IM rotation are unfair. She expects a resident/attending level of medical decision making. Iâ€™ve used ChatGPT to answer some of her ridiculous pimping questions but she still gives me â€œhomeworkâ€. The other day, we had a CHF patient admitted for anasarca. His EF was really low. She asked me why the patient was given Bumetanide and Metolazone when heâ€™s already on Furosemide at home. I told her because those two are fast acting and help take the fluid off more efficiently. She wasnâ€™t impressed. She gave me a hmm and then asked me next steps for this patient. â€œWeâ€™re paying $4,000 a day to keep this guy admitted. What should you do? Discharge him home? Admit?â€ At this point, I told her to admit because of the low EF and take the fluid off and consult cardiology. I told her to either increase his Furosemide dose at home or put him on another diuretic. â€œThatâ€™s not enough for me. You need to learn about heart failure and present to me the next day.â€ Okay, I guess. This preceptor will never explain anything. Itâ€™s always â€œgo learn thisâ€.

Any tips on where I can find ways to come up with a plan? Is there any free resource out there I can use besides progress notes from other physicians? She gets upset when I use other progress notes even though she copies and pastes those same progress notes for her own notes in the chart.",User_deleted,25
1fxyen2,1,2024-10-06,"What is up with the so called self proclaimed "" Strong Independent Woman"" a trend very common in recent Gen z and millennial women who are working in a job. I have described a strong Reality check to these women in this post. what are you guys' opinions on this ? Please let me know.",u/Lazy-Discipline-4203,IndiaCareers,https://www.reddit.com/r/IndiaCareers/comments/1fxyen2/what_is_up_with_the_so_called_self_proclaimed/,"I think Diversity hiring is unfair and is a discrimination towards Men and discredits meritocracy and has social implications.  
The job market is very tight since last 15-20 months, But Many foreign companies in India especially the American and European continue to aggressively push diversity hiring that many capable male candidates are left unplaced and Girls even with slightly less skill get easily employed. Since foreign companies have better pay and facilities than Indian counterparts, this creates a social imbalance as men earning less than girls or men working in low grade indian companies will be viewed as failed or worthless and Girls' ego boosts as she proclaims herself as a ""Strong Independent Girl"" which actually is a delusion and such girls think ""Males are inferior to them"" and they become entitled and feel that they must dream big and talk about My career My career shit while boys still thinking about Family's economic situation in tough market.

Example: Literally every 2nd girl in this university called ""IGDTUW"" is placed in Microsoft , Uber , Amazon , CISCO to the extent and quantity as if these companies were mass recruiters.

Of All my Guy and Girl acquaintances which had similar skillsets, almost all the girls have got placed very easily (even the girls with slightly less skills and projects) while guys still finding jobs thanks to ""THE RESERVATION GIRLS GET "" by many companies like EY, Deloitte, KPMG, S&P Global, CapGemini,Morgan Stanley , Goldman and Many more.

If Any of you people are working just check the proportion of females in HR/Operations roles into your company, the proportion of females so damn high like 70-80% as if HR positions in a company too are reserved for Women.

Infact during placement drives there are many companies who conduct ""Women only"" drives and straightaway exclude men from the hiring process.

So all the working women before proclaiming yourself as ""Strong Independent OverAchiever"" wake upto the reality. A lot of girls are gifted Jobs , they didnot earn it.

See the Data , the fresher Job placements for females skyrocketed despite overall weak job creation. This shows that A lot more number of women are hired than men even though there are 3-4 times more men in higher education and job seekers, This proves that women are hired at the expense of men.  
[https://www.livemint.com/industry/human-resource/women-freshers-placements-grew-116-yoy-in-2023-report-11710908805490.html](https://www.livemint.com/industry/human-resource/women-freshers-placements-grew-116-yoy-in-2023-report-11710908805490.html)  
[https://economictimes.indiatimes.com/jobs/fresher/private-engineering-colleges-see-50-70-drop-in-placements/articleshow/105154189.cms?from=mdr](https://economictimes.indiatimes.com/jobs/fresher/private-engineering-colleges-see-50-70-drop-in-placements/articleshow/105154189.cms?from=mdr)  
[https://timesofindia.indiatimes.com/city/mumbai/at-end-of-iit-bombay-placements-only-75-get-jobs-lowest-pay-down-to-rs-4l/yr/articleshow/113007058.cms](https://timesofindia.indiatimes.com/city/mumbai/at-end-of-iit-bombay-placements-only-75-get-jobs-lowest-pay-down-to-rs-4l/yr/articleshow/113007058.cms)  
[https://timesofindia.indiatimes.com/business/india-business/tech-slump-large-batches-deal-a-blow-iits-struggle-to-find-placements-for-students-low-paying-jobs-being-rejected/articleshow/109210392.cms](https://timesofindia.indiatimes.com/business/india-business/tech-slump-large-batches-deal-a-blow-iits-struggle-to-find-placements-for-students-low-paying-jobs-being-rejected/articleshow/109210392.cms)",active,0
1fxzo0h,1,2024-10-07,"How I Graduated College with No Internships, a Low GPA, and Multiple Fâ€™s â€” Yet Still Landed an IT Job",u/anonjit,ITCareerQuestions,https://www.reddit.com/r/ITCareerQuestions/comments/1fxzo0h/how_i_graduated_college_with_no_internships_a_low/,"Let me be real with you. I was an awful college student, and it took me six long years to finally graduate. Iâ€™ve seen enough Reddit posts romanticizing college struggles, but this is not one of those stories. This is my rollercoaster of a journey through college, complete with failing grades, lack of motivation, and somehow still managing to find an IT job at the end.

It all started like any typical college experience. I was optimistic, motivated, and doing fairly well in my first year. Then 2020 hit, and COVID wrecked any drive I had. By the time my sophomore year rolled around, my motivation was completely gone. I stopped going to class, stopped doing homeworkâ€”basically stopped caring about school altogether.

At one point, I seriously considered dropping out. When I told my mom, she broke down in tears and wouldnâ€™t let me, so I stayed. But things only got worse. I kept failing classes, and eventually, I was placed on academic warning. Thatâ€™s when I decided to switch my major from Computer Engineering to IT, hoping it would be a fresh start. Spoiler: It wasnâ€™t.

COVID continued, and my academic career kept spiraling downward. Junior year? Flunked that too, with multiple Fâ€™s again. This time I was placed on academic probation, and I still didnâ€™t care. I was convinced I was going to drop out anyway, but when I told my mom again, she refused to hear it. So, I stuck it out. My second semester of junior year was no betterâ€”I failed another class and stayed on probation.

Fast forward to senior year. Miraculously, I did great during my first semester. I finally felt like I was turning things around. But by the second semester, I hit a wallâ€”Discrete Math. I bombed it and ended up on probation again. Honestly, I shouldâ€™ve been kicked out, but COVID was considered an â€œextenuating circumstanceâ€ that saved me.

At that point, I was 22 and had no direction. Thatâ€™s when I heard about cybersecurity and the big money people were making. I knew I needed to get serious. So, I buckled down and made sure I passed all my classesâ€”mostly by cheating. By the time I pulled my GPA up enough to consider internships, it was too late. I had a 6-year degree with a transcript full of Fâ€™s, no internships, no experience, and no references.

I figured I was screwed in the job market. I didnâ€™t have much to sell, but I had LinkedIn, and I wasnâ€™t about to waste it. So, I optimized the hell out of my profile. I stretched every tiny project I had ever done in college into something impressive. That half-baked Excel sheet? â€œData analysis and visualization project.â€ That Cloud-Based Inventory Management System app that i built? That was really just ChatGPT doing all the work. Yeah, I donâ€™t even know how to code, but I upsold the heck out of it as â€œdeveloped a Cloud-Based Inventory Management System mobile app.â€ I looked up coding languages because it seemed like the thing to do in IT, but letâ€™s be honestâ€”I was mostly winging it.

In total, I applied to over 1,000 jobs, expecting nothing. But, somehow, I got hired as a very low-tier Solutions Architect in Georgia. Sounds cool, right? Well, hereâ€™s the kickerâ€”I donâ€™t know jack about IT. The job pays in the low $20s an hour, and Iâ€™m basically learning as I go. (Actually received about 12 interviews since May but got rejected because of â€œno experienceâ€). 

So yeah, college was a disaster. But hey, if I can manage to get a job after all that, maybe thereâ€™s hope for anyone. Even if you donâ€™t have a clue what youâ€™re doing. Also, my soft skills are carrying me right nowðŸ«¡",User_deleted,1
1fyaf84,1,2024-10-07,"How I Graduated College with No Internships, a Low GPA, and Multiple F's â€” Yet Still Landed an IT Job",u/anonjit,ITCareerQuestions,https://www.reddit.com/r/ITCareerQuestions/comments/1fyaf84/how_i_graduated_college_with_no_internships_a_low/,"Let me be real with you. I was an awful college student, and it took me six long years to finally graduate. I've seen enough Reddit posts romanticizing college struggles, but this is not one of those stories. This is my rollercoaster of a journey through college, complete with falling grades, lack of motivation, and somehow still managing to find an IT job at the end.
It all started like any typical college experience. I was optimistic, motivated, and doing fairly well in my first year. Then 2020 hit, and COVID wrecked any drive I had. By the time my sophomore year rolled around, my motivation was completely gone. I stopped going to class, stopped doing homework-basically stopped caring about school altogether.

At one point, I seriously considered dropping out. When I told my mom, she broke down in tears and wouldn't let me, so l stayed. But things only got worse. I kept failing classes, and eventually, I was placed on academic warning. That's when I decided to switch my major from Computer Engineering to IT, hoping it would be a fresh start. Spoiler: It wasn't.

COVID continued, and my academic career kept spiraling downward. Junior year? Flunked that too, with multiple F's again. This time I was placed on academic probation, and I still didn't care. I was convinced I was going to drop out anyway, but when I told my mom again, she refused to hear it. So, I stuck it out. My second semester of junior year was no better-| faileu another class and stayed on probation.

Fast forward to senior year. Miraculously, I did great during my first semester. I finally felt like I was turning things around. But by the second semester, I hit a wall-Discrete Math. I bombed it and ended up on probation again. Honestly, I should've been kicked out, but COVID was considered an ""extenuating circumstance"" that saved me.


At that point, I was 22 and had no direction. That's when I heard about cybersecurity and the big money people were making. I knew I needed to get serious. So, I buckled down and made sure I passed all my classesâ€” mostly by cheating. By the time I pulled my GPA up enough to consider internships, it was too late. I had a
6-year degree with a transcript full of F's, no internships, no experience, and no references.

I figured I was screwed in the job market. I didn't have much to sell, but I had Linkedin, and I wasn't about to waste it. So, I optimized the hell out of my profile. I stretched every tiny project I had ever done in college into something impressive. That half-baked Excel sheet? ""Data analysis and visualization project."" That Cloud-Based Inventory Management System app that i built? That was really just ChatGPT doing all the work.
Yeah, I don't even know how to code, but l upsold the heck out of it as ""developed a Cloud-Based Inventory Management System mobile app."" | looked up coding languages because it seemed like the thing to do in IT, but let's be honestâ€”| was mostly winging it.
In total, I applied to over 1,000 jobs, expecting nothing.

But, somehow, I got hired as a very low-tier Solutions Architect in Georgia. Sounds cool, right? Well, here's the kicker-I don't know jack about IT. The job pays in the low $20s an hour, and I'm basically learning as I go.
(Actually received about 12 interviews since May but got rejected because of ""no experience"").
So yeah, college was a disaster. But hey, if I can manage to get a job after all that, maybe there's hope for anyone. Even if you don't have a clue what you're doing. Also, SOFT SKILLS ARE EVERYTHING ðŸ«¡",User_deleted,0
1fzurbz,25,2024-10-09,A Guide to the Understanding of LLMs | walking through 11 papers | incl 10 minute NotebookLM podcast!,u/cyan2k,singularity,https://www.reddit.com/r/singularity/comments/1fzurbz/a_guide_to_the_understanding_of_llms_walking/,"*Pre-text:* This was originally posted for /r/localllama, but I thought it wouldn't hurt if you guys also get some education. So if I rant on someone or something, don't be sad, it's not about my singularity boys. I love you.

This is going to be a looooong post reviewing around 11 research papers on the topic of ""Understanding"" in the context of LLMs. If you hate reading, check out this NotebookLM with all the sources to chat with and Podcast to listen to included! https://notebooklm.google.com/notebook/7ab05f1f-6256-4d7b-9072-5030de7e78fa?hl=en (It took like 20 generations until I got a decent podcast! So listen to it!)

Iâ€™ve selected sources that are accessible for hobbyists and are published by a top university or Google. If youâ€™re not as dumb as a rock and can handle basic logic and math, youâ€™ll grasp the core ideas in these papers. 
Also to facilitate better understanding some parts are not exactly 100% accurate to the linked paper, but I tried to keep it as close as possible while still being understandable by the layman.

Letâ€™s dive in.


---------------------------------------

## Intro

So, the recent thread about Hinton made me question the sub's (and my) sanity.

For those out of the loop, Nobel Prize winner Hinton, the ""godfather of AI,"" mentioned in his speech that he hopes his words, that LLMs understand, now carry more weight, especially regarding risks and possibilities.

When I heard him, I thought he was talking about how the average Joe has no clue what LLMs can and canâ€™t do. Itâ€™s tough to explain, so good for him. ""Nobel Prize Winner"" is quite a credential for the Joes out there.

What I didnâ€™t expect was this sub to completely implode. And for what reason? There are more than 30 papers on LLM ""mental capabilities"", and those are just the ones Iâ€™ve read. Itâ€™s basically common knowledge that, yes, of course, LLMs understand. But apparently, itâ€™s not. People were spiraling into debates about consciousness, throwing around ad-hominem attacks, and even suggesting that Hinton has forgotten how to be a scientist, because he just stated an opinion, and even worse! an, according to the brains of reddit, WRONG opinion! Who does this fuck think he is? The Einstein of AI? Pffff. 
All the while, I didnâ€™t see a single attempt to disprove him.... just... also opinions? Funny.

I argue Hinton didnâ€™t forget to be a scientist. This sub just never was one. A real scientist would know all the papers, or at least be aware of them, that back up Hinton. So the complete shitshow of a thread caught me off guard. Hinton knows the research, which is why he said what he did. And I thought this sub also knows its science, because it is literally about bleeding edge science.
I always thought, every time someone was saying ""statistical parrot"" , it's like a meme, in the same sense like you do ""and the earth is flat herp derp"" because we are far beyond that point already. But now I'm not so sure anymore.

So, Iâ€™m here to fine-tune the meat-transformer in your head and give you a summary of a bunch of the papers Iâ€™ve read on this topic. If I missed any important that has to be in this list, drop a comment. And hey, I already won my first challenge. Some nice guy via PM claimed that I'm not able to produce even a single paper hinting in the slightest that LLMs have some kind of capability to understand. Thanks for the nicely worded PM stranger, I hope you also find peace and happiness in life.

And who need hints, when he has evidence? So let's get into it! Weâ€™ll go slow on this, so Iâ€™ll keep the learning rate low and the batch size at 1. And for those who need it spelled out: evidence does not equal proof, so save your semantic smart assery.

We will explore the ""inner world"" of an LLM, then examine how it interprets the ""outer world"" and ""everything beyond"". We'll top it off by discussing the consequences of these perspectives. Finally, we'll look at an area where LLMs can still improve and engage in a philosophical thought experiment about what might await us at the end of the rainbow.

## Emergent Abilities

Let's start with some conceptual definitions:

Understanding != consciousness. I don't know why, but somehow people in Hinton's thread thought he meant LLMs are conscious, as if theyâ€™re living entities or something. He didnâ€™t.

Thereâ€™s quite a jump from what â€œunderstandingâ€ means in computer science and AI research to consciousness. The word ""understanding"" doesn't exist in a CS researcherâ€™s vocabulary (except when talking to the public, like Hinton did) because it's a fuzzy concept, too fuzzy to base research on it indeed, as you could see in that thread. 

But in science, we need a conceptual frame to work in, something you can define, which is how ""understanding"" got replaced by ""emergent abilities"". Emergent abilities are abilities an AI learns to do on its own, without being explicitly trained or designed for it. And to learn something independently, a model needs to generalize its existing knowledge in ways that go beyond simple token output. Over the course of this post we will look how a text generator can do vastly more than just generating text....

Here's a quick primer from Google on ""emergent abilities"":  
[https://research.google/blog/characterizing-emergent-phenomena-in-large-language-models/](https://research.google/blog/characterizing-emergent-phenomena-in-large-language-models/)

#### Most interesting takeaway:

The biggest bomb of all: We donâ€™t know why, when, or what. We have absolutely no idea why or when these emergent abilities kick in; Emergent abilities donâ€™t appear gradually but instead pop up suddenly at certain model scales, like a critical threshold was crossed. Whatâ€™s really going on at that point? What exactly is it that make that points so special? Can we predict future ""points of interest"". Some argue it's the single most important question in AI research. And to those people who like to argue ""we can't scale infinitely"", I argue it really depends on what kind of emergence we find... or finds us....

Imagine training a model on separate French and English texts. Nothing happens for a while, and then *boom* it can translate between the two without ever seeing a translation. It suddenly gained the emergent ability to translate. Sure, call it a statistical parrot, but if a parrot could do this, itâ€™d be one hell of an intelligent parrot.

But I get it. Even tho seven years ago, you would have been downvoted into oblivion on r/machinelearning for suggesting that there's some random ""upscale"" point where a model just learns to translate on its own. It wouldnâ€™t have even registered as science fiction. Itâ€™s crazy how fast the bleeding edge becomes everyday life, to the point where even a model that could beat the Turing test isnâ€™t mind-blowing anymore. Weâ€™ve become too smart to be impressed, dismissing models that use our own mediums for representing the world as ""just statistics,"" because an LLM â€œobviouslyâ€ has no real world representationâ€¦ right? Well... or does it?

*(please hold your horses, and don't try to argue the Turing Test with me, because I know for a fact that everything you are going to say is a misinterpretation of the idea behind the test, probably something you got from the one afro american TV physicist I don't remember the name of, because I'm not from the US, or some other popular science shit and therefore is basically wrong. Just know, there was a time, not that long ago, when if you asked any computer scientist when weâ€™d solve it, youâ€™d get answers ranging from â€œneverâ€ to â€œhundreds of years, and it really was like the north star guiding our dreams and imagination, and we are now at a point where people try to forcefully move the turing-goalposts somewhere out of the reach of GPT. And the ones who don't feel like moving goalposts every two weeks (especially the younger ones who don't know the glory days) take the easy route of ""This test is shit"" lol. what a way to go sweet Turing test. this process from beacon to trash is all I wanted to share. so, leave it be.)
*

## My inner world...

[https://arxiv.org/abs/2210.13382](https://arxiv.org/abs/2210.13382)

#### Most interesting takeaway:

In Monopoly, you have two main things to track: your piece and your money. You could note down each round with statements like, ""rolled a 6, got 60 bucks"" or ""rolled a 1, lost 100 dollars"" until you have quite a few entries.

Now, imagine giving this data to an LLM to learn from. Even though it was never explicitly told what game it was, the LLM reverse-engineers the gameâ€™s ruleset. The paper actually used Othello for this experiment, but I guess itâ€™s not as popular as Monopoly. Regardless, the core idea remains the same. Just by the information about how the players state changes the LLM understands how the game state changes, and what constraint and rules for those game states exist. So it came up with it's own... well not world yet, but boardgame representation.

And thatâ€™s not even the coolest part the paper showed. The coolest part is that you can actually know what the LLM understands and even prove it. Encoded in the LLMâ€™s internal activations is information it shouldnâ€™t have. How can you tell? By training another AI that detects whenever the LLMâ€™s internal state behaves a certain way, indicating that the 'idea' of a specific game rule is being processed. Doesn't look good for our parrot-friend.

That's btw why plenty of cognitive scientists are migrating completely to AI because of the ability to ""debug"" 

Perhaps you are asking yourself ""well if it understands the game rules how good is it in playing such game then?"" we will answer this question in a bit ;)

## ...and my outer world...

Imagine going out with your friends to dine at the newest fancy restaurant. The next day, all of you except one get the shits, and you instantly know that the shrimp is to blame because your friend who is painting his bathroom with a new color was the only one who didnâ€™t order it. Thatâ€™s causal reasoning. I like to call it ""knowing how the world works"" This extends beyond board game rules to any ""worldgame"" that the training data represents.

[https://arxiv.org/abs/2402.10877#deepmind](https://arxiv.org/abs/2402.10877#deepmind)

#### Most interesting takeaway:

Some Google boys have provided proof (yes, proof as in a hard mathematical proof) that any agent capable of generalizing across various environments has learned a causal world model. In other words, for an AI to make good decisions across different contexts, it must understand the causal relationships in the data. There it is again, the forbidden Hinton word.

The paper is quite math-heavy, but we can look at real-world examples. For instance, a model trained on both code and literature will outperform one trained solely on literature, even in literature-only tasks. This suggests that learning about code enhances its understanding of the world.

In fact, you can combine virtually any data: learning math can improve your French botâ€™s language skills. According to this paper, learning math also boosts a model's entity tracking ability.

[https://arxiv.org/pdf/2402.14811](https://arxiv.org/pdf/2402.14811)

Coding improves natural language understanding, and vice versa.

With extremely potent generalization (which, by the way, is also a form of understanding), a models can generalize addition, multiplication, some sorting algorithms ([source](https://arxiv.org/html/2405.17399v1)), and maybe even a bit of Swahili (this was a joke, haha). 
This indicates that models arenâ€™t just parroting tokens based on statistics but are discovering entirely new semantic connections that we might not even be aware of. This is huge because if we can reverse engineer why math improves a modelâ€™s French skills, it could offer insights into optimization strategies we aren't even aware of their existence, opening up countless new research angles. Thanks, parrot!

Like when people talk about ""AI is plateauing"" I promise you... the hype train didn't even started yet, with so much still to research and figure out.....

## ...and the whole universe

All of this leads us to reasoning. Youâ€™re not wrong if you directly think of O1, but thatâ€™s not quite correct either. Weâ€™re talking about single-step reasoning, something everyone knows and does: ""Hey ChatGPT, can you answer XXXX? Please think step by step and take a deep breath first."" And then it tries to answer in a reasoning chain style (we call these reasoning graphs), sometimes getting it right, sometimes wrong, but thatâ€™s not the point.

Have you ever wondered how the LLM even knows what ""step by step"" thinking means? That it means breaking down a problem, then correctly choosing the start of the graph and building the connections between start and finish. In state-of-the-art models, there are huge datasets of reasoning examples fed into the models, but these are just there to improve the process; the way of thinking it figured out itself. Itâ€™s all about internal representations and ""ideas""

Good ol' Max did a paper showing LLMs even have an understanding of space and time. Btw, if you see the name Max Tegmark, you have to read whatever heâ€™s written. Itâ€™s always crazy town, but explained in a way that even a layman can understand. You might think, ""Okay, I got it by processing trillions of tokens, some spatial info just emerges"" and itâ€™s some abstract 'thing' deep inside the LLM we canâ€™t grasp, so we need another AI to interpret the state of the LLM. 

But hereâ€™s where it gets fun.

[https://arxiv.org/pdf/2310.02207](https://arxiv.org/pdf/2310.02207)

They trained models on datasets containing names of places or events with corresponding space or time coordinates spanning multiple locations and periods - all in text form. And fucking Mad Max pulled an actual world map out of his ass the model that even changes over time based on the learned events.


Another paper also looked into how far apart can dots be so the LLM can still connect them

>In one experiment we finetune an LLM on a corpus consisting only of distances between an unknown city and other known cities. Remarkably, without in-context examples or Chain of Thought, the LLM can verbalize that the unknown city is Paris and use this fact to answer downstream questions.
  
https://arxiv.org/abs/2406.14546


## Checkmate ~~atheists! technophobes! technophiles!~~ luddites!

And boy, the dots can be universes apart. I mean, you probably know chess, a very difficult game to master. Yet, our little text prediction friend can somehow also play chess! When trained on legal moves, it will also play legal chess (back to our board game example). But how good is it? Well, naturally, some Harvard Henrys looked into it. They found that when trained on games of 1000 Elo players... what do you think, how good is the LLM? Spoiler: >!1500 Elo!<


[https://arxiv.org/pdf/2406.11741v1](https://arxiv.org/pdf/2406.11741v1)

Say what you want, but for me, this isnâ€™t just evidence, itâ€™s hard proof that some understanding is happening. Without understanding, thereâ€™s no way it could learn to play better chess than the players it observed, yet here we are. When trained on data, LLMs tend to outperform the data. And I don't know what your definition of intelligence is, but it hits pretty close to mine. Here you have it, you can still have opinions in science, without being a dick to scientists! crazy I know. Like, sorry for ranting, one guy in the thread was like ""Now my opinion of Hinton is ruined"", like obviously the guy doesn't know shit if he's mad on someone saying ""LLMs understand"", but somehow it's of great importance that he felt the need to also announce his ignorance and opinion into the world. 

Why? 

Takes literally 30s to google ""LLMs understanding paper"" to be buried with 50 hits on arxiv. People rather shit on people instead of taking five second from their clock to perhaps gain the chance to challenge their own view point of things. It wasn't always like this, was it?


## Just google it, bro


Another example would be recognizing zero-day vulnerabilities. 
For those who don't know what those funny words mean: 
When software get updated, and because of the update there is a new stupid bug, and this stupid bug is a pretty intense bug that fucks everything and everyone, and nothing works anymore, and you have to call your sysadmin on Sunday, and fucking shit why is he so expensive on Sundays, why does this shit always happen on sundays anyway?, thatâ€™s called a ""zero-day vulnerability"" 

Recognizing these is important, so there are vulnerability scanners that check your code and repository (basically trying to hack them). If any of your dependencies have a known ""0day"" itâ€™ll notify you so you can take action.


Whatâ€™s the discovery rate for an open-source vulnerability scanner? A tool specifically made for the task!

  
Close to 0%.


I kid you not, most of them only recognize 0days one or two days later when their database updates, because their scanning algorithms and hacking skills suck ass.

GPT, on the other hand, has a 20% discovery rate, making our little waifu story generator one of the best vulnerability scanners out there (next to humans). 

**DISCLAIMER***(There's a huge discussion in the community because of the methodology used in the paper, because GPT as an agent system had internet access and basically googled the exploits instead of figuring them out itself, but I chose to include it anyway, because this is how every 'security expert' I know also works. Also tool using is cool. Always cracks me up when AI gets measured more strictly than humans.)*


## Context is everything

Like with Hinton and the meaning of ""understanding,"" context is also super important when talking about LLMs. 
Some might say, ""Ok, I get it. I understand all this talk about training! When you train a model on trillions of datapoints for millions of dollars over thousands of hours, something happens that makes it _seem_ like it understands things."" 

But they still think they have an out: in-context learning! 

""BUT! A system that truly understands wouldnâ€™t be so dumb when I give it new information, like --INSERT BANANA PUZZLE-- (or some other silly example, which even humans fail at, by the way). GOT YA!""

And I agree, in-context learning and zero-shot learning are still areas that need more research and improvement (and thatâ€™s why we arenâ€™t plateauing like some think). But even here, we have evidence of understanding and generalization. Even with completely new information, on completely new tasks, as shown by this Stanford article:

[https://ai.stanford.edu/blog/understanding-incontext/#empirical-evidence](https://ai.stanford.edu/blog/understanding-incontext/#empirical-evidence)

If you think about what the article say, you can see how this disproves the ""statistical parrot"" theory, proving thereâ€™s more going on than just predicting the next token.

And perhaps you remember my XTC Sampler thread? 

For those who donâ€™t know, the XTC sampler is a LLM token sampler that cuts away the MOST probable tokens to allow more creativity. 

People in the thread would say, ""But doesnâ€™t that make the model unusable?"" 

No, it still does what it does. 

Even if you only let sub-1% tokens through, it still produces coherent text! 

even at the limits of its probability distribution, when the information encoded in the tokens is so improbable it shouldn't be coherent at all, but hereâ€™s the kicker: even when I cut away all the popular tokens, it still tells roughly the same story. This means the story isnâ€™t encoded in the stream of tokens but somewhere within the LLM. No matter what I do with the tokens, itâ€™ll still tell its story. Statistical Parrot, my ass.

## Where does it lead us?

Who knows? 
It's a journey, but I hope I could kickstart your computer science adventure a bit, and I hope one thing is clear: 

Hinton didnâ€™t deserve the criticism he got in this thread because, honestly, how can you look at all these papers and not think that LLMs do, in fact, understand? 

And I also donâ€™t get why this is always such an emotionally charged debate, as if itâ€™s just a matter of opinion, which it isnâ€™t (at least within the concept space we defined at the beginning). 

Yet, somehow, on Reddit the beacon of science and atheism and anime boobas, only one opinion seems to be valid. like also the most non-science opinion of all. 

Why? I don't know, and honestly I don't fucking care, but I get mad if someone is shitting of grampa Hinton.

Well, I actually know, because we recently did a client study asking the best question ever asked in the history of surveys:

â€œDo you enjoy AI?â€ (sic)

 
90% answered, â€œWhat?â€

Jokes aside, most people are absolutely terrified of the uncertainty it all brings. 
Even a model trained on ten Hintons and LeCuns couldn't predict where weâ€™re heading before it self destructs. 

Does it end in catastrophe?

Or is it just a giant nothingburger? 

Or maybe it liberates humanity from its capitalist chains, with AGI as the reincarnated digitalized Spirit of Karl Marx leading us into utopia.

As you can see, even the good endings sound scary as fuck. 

So, to avoid making it scarier than it already is, people tell themselves, â€œItâ€™s just a parrot, broâ€ or â€œItâ€™s just mathâ€, like saying a tiger that wants to eat you is just a bunch of atoms. 
In the end, if I had a parrot that could answer every question, it doesnâ€™t matter if itâ€™s â€œjust a parrotâ€ or not. The mobile phone number of your mum is mine anyway, and â€œitâ€™s just a parrotâ€ wonâ€™t save you from that reality. 

So, better to just relax and enjoy the ride, the roller coaster already started and there's nothing you can do. 
In the end, what happens, happens, and who knows where all of this is leading usâ€¦

This paper from MIT claims it leads to the following (donâ€™t take it too seriously, itâ€™s a thought experiment): All neural networks are converging until every model (like literally every single model on earth) builds a shared statistical model of reality. If thereâ€™s anything like science romanticism, this is it. 

""Hey babe, how about we build a shared statistical model of reality with our networks tonight?""

https://arxiv.org/abs/2405.07987

  


In that sense, have a good one, and maybe we can dive into the counterarguments next time :)

Or if you have any other idea of something you want a deep dive into, let me know. Do you for example know, that in a blind test Professors can't decide if a paper abstract is written by GPT or one of their students? Or did you know, that LLMs literally have their own language? Like there exists (probably?) an infinite amount of words/prompts that look like this ""hcsuildxfz789p12rtzuiwgsdfc78o2t13287r"" and force the LLM to react in a certain way. How and why? well... it's something for future me... perhaps ;)",User_deleted,23
1fzxtt5,1,2024-10-09,Is it reasonable for me to switch out of my honors class because i have an F?,u/Green-Bath-6943,Advice,https://www.reddit.com/r/Advice/comments/1fzxtt5/is_it_reasonable_for_me_to_switch_out_of_my/,"I have been absent from school for the past 2 weeks because i had a decaying tooth and something happened where my entire mouth was in excruciating pain for a week. I ended up getting the tooth removed, then getting dry socket. So i was absent for a while. In the meantime of me being absent i tried getting as much schoolwork done that i missed as possible. I currently have an F in every class and its because im missing a test in some classes. 

I take honors classes, but for my english class (which english is my favorite subject) i have the worst teacher and shes making me hate it. I would transfer into a different class, but unfortunately she is the only teacher who teaches honors english. 

I had a stupid quiz on a crash course video today and i got a 18/30. The only reason i even got that grade was because it was on one of those sites if you press something, thats automatically your answer and you cant go back. I pressed 2 questions wrong by accident because i clicked to the next question which yes, is my fault but when i told my teacher she said thats not her problem and i shouldve been more careful. I understand that yes, it very much was my fault but i was maybe hoping she could just let me retake it..

Today, she emailed my mother telling her that i do not belong in a honors english class and that i should consider transferring to cp. I have always gotten good grades in my honors classes and i never had a problem with them. 

I dont think im going to take her â€œadviceâ€ but im now in trouble for having such bad grades even though in some other classes, my teachers didnt even notice i was absent and wont take any â€œlateâ€ work (even though i was absent and the work was due before i came back)

She also accuses students of using chatgpt if their essays are good. 

Im really struggling and just need some advice on what to do .",User_deleted,0
1g1zd7f,27,2024-10-12,ChatGPT is a learning assistant I always wanted,u/Organic-Maybe-5184,ChatGPT,https://www.reddit.com/r/ChatGPT/comments/1g1zd7f/chatgpt_is_a_learning_assistant_i_always_wanted/,"I'm a developer and it always irked me that I suck at math. I tried to improve that by downloading books and reading them, but lead to much frustration because most concepts are vaguely described or I can't make them work in combination. I didn't want to ask badly worded vague questions on task that would be left unanswered (done that). Which is why I abandoned each my attempt to learn.

Recently I dived into Bayesian statistics for my personal project and use ChatGPT as a learning assistant - I uploaded the book there and ask relevant questions. It even understands screenshots. I'd give up this project long ago if not for this tool. It is wonderful at connecting different topics and explaining how they work together, or just answering questions. It is so refreshing to have something that has your back if you have difficulties. Sure, you need some understanding to verify responses.

Some people say that ChatGPT gonna kill education, but it's contrary to me (although I'm not a student).",User_deleted,26
1g4rhsx,25,2024-10-16,Finally got one,u/RuralCapybara93,Professors,https://www.reddit.com/r/Professors/comments/1g4rhsx/finally_got_one/,"Well, Im an adjunct who only teaches on or two courses a semester, so maybe I was overdue and just dont teach enough students for it to have happened. 

I had a student submit an assignment and at the bottom of the assignment, it says that it was written by chatgpt. It was signed by the program.

I've suspected they've been using it, but this was their first mess up. Presumably they've been turning it in straight, so I'll say I am surprised that it has been doing citations and in-text citations correctly. 

They got a zero, but no institutional support to report the student or do anything else. They just get the zero for that one course. Not sure what else I should do, but I hate that the students actually doing the work get similar grades to this person. 

System just seems broken. ",User_deleted,26
1g7ygs1,2,2024-10-20,"How did you convince yourself to get a PhD, despite all the negative reasons given to not pursue one?",u/BlueSea9357,PhD,https://www.reddit.com/r/PhD/comments/1g7ygs1/how_did_you_convince_yourself_to_get_a_phd/,"- PhDs in most fields are told that they're not worth much to industry compared to masters/bachelors students. Even in a field that's good today, there is no guarantee it'll even exist 6 years from now.

- Academia is a dumpster fire, to put it mildly. Too many applicants, not enough jobs, extreme elitism, paid very little, and you're still bottom of the totem pole.

- Research jobs in industry are kind of antonyms, industries want immediate profit, and ""research"" isn't really a thing you can guarantee results from

- Master's student admissions are a piece of cake compared to PhD admissions, allowing them to focus purely on what they want to learn, instead of the huge barriers there are to a PhD program (e.g. Standford M.S. vs Harvard PhDs are in entirely different universes for applicant requirements, like the difference in difficulty between bachelors at a no-name school and admission into a medical school)

- Fudging of data and ChatGPT are probably taking their toll on how seriously outsiders take research. Only so much research data can be faked before it starts to reflect on everyone, even if most people don't do it.

How did you convince yourself to get a PhD? I really like learning more through an MS program, and research is okay, but it seems like most ""research"" careers are either dead end from the start, or you can quickly become useless if your topic of research is no longer relevant.",User_deleted,1
1g7z27d,7,2024-10-20,Online Course,u/DecentFunny4782,Professors,https://www.reddit.com/r/Professors/comments/1g7z27d/online_course/,"This summer I am slotted to teach a class I usually teach on campus, online. It will be an 8 week class rather than a 16 week class. In the regular class I give them exams in class and a short essay. It seems no matter what I do in the summer version it will be nowhere near as rigorous. Give them exams? They will look up the answers. Give them an essay? They will use chatgpt. 

So nasically, it seems like unless I come up with good ideas to keep them accountable, the summer students will have a much easier time with the course, which just seems blatently unfair.

Is there any way to avoid this? Is this something that is known by universities and the online classes are just offered without acknowledging that the on campus students are being held accountable while online students are not? Are inline classes basically a scam that everyone just hushes about? Thinking about not teaching the class, even though I could use the money.",User_deleted,7
1g9q4ud,47,2024-10-22,iSchool Expectations/Accountability Rant,u/swamblies,UMD,https://www.reddit.com/r/UMD/comments/1g9q4ud/ischool_expectationsaccountability_rant/,"TLDR; iSchool does not hold students accountable for actually understanding the material. The classes aren't necessarily 'easy' themselves (difficult enough concepts/assignments/etc.), but they just hand out A's like we are in elementary school. The expectations are nonexistent. People get away with it through the excessive amount of group work and using generative AI, and I wish so badly that projects were solo because they'd just be less work than babysitting a bunch of adults with lackluster performance.

Disclaimer: I am not saying this is ALL iSchool students/professors/classes. This is just a trend I have experienced myself over and over and I am so sick of it.

I am an Information Science major for reference (along with another major & minor in CMNS). I took on the major last year. Going in, I thought it was going to live up to the expectation that everyone gave it: easy enough, full of comp sci dropouts, some projects but not nearly as much outside work as comp sci, etc.

Since being in the major, I have realized its more than just ""easy comp sci."" Not only do the rooms stink just as bad of B.O. as the computer science classes, but many students are incredible slackers/cheaters and the professors rarely hold them accountable. At least in comp sci (I assume) students literally cannot slack off without failing a class (seen it happened to several people freshman year who chose League of Legends over CompSci).

 Scrolling through weekly discussion posts, I see the same conventions being used again and again with the same comments, evident that students are either copying from previous posts or all just using AI like ChatGPT to write their code/discussion post. I am willing to bet that half of these people graduate with an Information Science degree and can't write a program more than 50 lines without the use of generative AI. To clarify, I do think that AI can be very helpful when learning (asking it what certain functions do, to help you remember the name of a function, explain syntax, debugging, etc.), it just shouldn't be used to straight up complete assignments.

The classes themselves are not as ""easy"" as they are made out to be. They're nothing crazy, but they do require some though to understand concepts like objects or keys. But they just don't seem to hold any students accountable for actually doing the work and understanding the material. People are passing these classes having not learned a thing. You can literally finish an ""intro to \[coding language\]"" class and pass with flying colors without knowing a thing about coding in that language.

In my other major, you HAVE to put in the work to get an A. Exam averages range from 50-70 and the grade distribution is a bell curve, with the peak being usually around a B or B-. These classes require you to put in work after class and practice what you learn independently. If you do not study outside of class, do the homework, and actually understand how to apply concepts, you will absolutely fail the class. I assumed that this was the case for all majors. In the iSchool though, I can't imagine anyone getting less than an A- in most of these classes unless they literally didn't do any assignments, simply because the expectation for many classes is less than the bare minimum. 

Many iSchool classes love to assign groupwork. This is a great idea in theory, since many of us will be pursuing careers that require us to work with others, since no one person can realistically write hundreds of thousands of lines of code within a ""normal"" timeframe. However, all these group projects are giving the opportunity for students to slack off further by waiting for the one or two people to do the work for them. I have spoken to several other upperclassmen iSchool majors who feel the same way. Almost every single group project I have been involved in within INST courses have included several underwhelming teammates who do less than the bare minimum. 

For instance, one of my classes required a formal write-up along with the final presentation of our project. I had word-for-word written out everything that my teammate needed to add to the document (I even wrote HER script for the presentation, which she read robotically off of instead of paraphrasing. Did none of these people take a communications class???). All she had to do was format my shorthand bullet points into a short paragraph. Instead, she simply copy and pasted the bullets into a formal essay that specifically asked for paragraph format, leaving me to do that entire section myself.

Also, loads of these classes are grading on completion??? We aren't in elementary school, there should be no ""participation"" awards. The average for major assignments hovers around 95% in many classes. Having seen what other people are submitting for these assignments, I am astounded that instructors are handing out full credit to the majority of students. 

For example, INST327 is many student's first introduction to SQL, a database coding language. The class itself is not exceptionally challenging, but it is understandable why many people would find learning a new coding language to be a daunting task. We have ONE weekly individual assignment graded on correctness. My professor decided to grade last week's individual assignment on completion AFTER everyone had submitted. The topic covered was arguably the most challenging subject in the entire class: Normalization. I spent hours going to TA office hours, communicating with the instructional staff, and working on it independently, just to get the same grade as the people who started it the night it was due (I am in a group for that class and they were all looking for help on the beginning of the assignment at 10pm that same night). Even worse, I looked over the answer key and saw that I did the entire process correctly, and will not be credited for that.

This is literally the only type of assignment in the class that holds people accountable for actually learning, understanding, and applying what we learn. This wouldn't be so bad if the only other assignments we have graded on correctness were the semester-long group project. This means that the lack of accountability towards these students indirectly impacts me through this group work. My group members have a concerning lack of understanding about SQL and have not once attended office hours to seek assistance. Not only do they have an inability to code, but they don't seem to have a conceptual understanding of databases either. For instance, one group member simply had to write 10 questions that our database could answer (who, what, when, where, why level questions. Nothing crazy or groundbreaking here; anyone could accomplish this without any coding knowledge). I went to look over the questions they wrote and not only were they incomplete, but every single one was completely unrelated to our database, meaning I had to do that section on top of what I was originally assigned to complete (the sections I ended up doing were literally worth over 50% of the entire assignment). Imagine having a database that listed employees names, date of hire, and where they got their college degree. A question you may ask would be ""from what college do we hire the most alumni?"" My group member was writing questions along the lines of ""how much money do our employees make,"" which is literally not available in that data.

This next group assignment for the project requires everyone in the group to understand and apply Normalization to our dataset. It includes a writeup about why we chose to Normalize in that specific way. It is the EXACT same thing as last week's individual assignment (the one that was spontaneously graded on completion). So basically, because nobody was held accountable for understanding Normalization with last week's assignment, I am once again stuck normalizing a complex dataset without the help of my group members (I have been communicating this to the instructional staff and there's not much to do besides give them poor ratings/explanations during peer-check ins). Even worse, because they also lack the conceptual understanding, I don't think they will be able to do the writeup either, since they can't explain relationships, linking tables, composite primary keys, etc.

My professor sent out an ELMS announcement to let the class know that last week's individual assignment was graded on completion. Myself and another student posted a public comment that we felt it was unfair and requested extra credit for the students who were correct. Another student replied ""I disagree since that would lower another idea and expectation, which leads to unfairness."" What does that even mean??? Not only is that sentence borderline unintelligible, but what on god's green earth could ""lead to unfairness"" when you give credit where credit is due and hole people accountable? Have we really sunk so low as to believing that on a college level, students applying their understanding to an assignment, and then being given a grade that reflects this, is somehow ""lowering an idea and expectation?"" I know we aren't an ivy league, but I really thought that UMD was better than this.

I'm genuinely so tired. I would have no problem doing these large projects solo over groups. It has become more work being in a group than just doing everything myself because I have to constantly be the one to reach out to them with reminders, tell them when to meet, set up meetings, ask them questions, tell them what they need to do, etc. Nobody ever seems to just figure out what they need to do on their own. Its like they need a chaperone to hold their had all the way through. I shouldn't have to feel like an elementary school teacher in a college level class. I've done everything in my power to try to communicate this to groups time and time again, and I've gone as far as reaching out to the instructors to request guidance. Its ridiculous that these people are getting the same grade as me for an assignment they didn't do so much as READ. I have to genuinely BEG group members to communicate, to come to a 20 minute weekly Zoom meeting, and to just DO their part of a project.

I'm literally exhausted for all the wrong reasons. It would be one thing if the course load was what was pushing me to my limits, but it is entirely the issue of how iSchool professors grade and how iSchool students act in group projects.

",active,54
1ga3ffo,9,2024-10-23,how can i dissuade this student from cheating?,u/swallowthedice,TutorsHelpingTutors,https://www.reddit.com/r/TutorsHelpingTutors/comments/1ga3ffo/how_can_i_dissuade_this_student_from_cheating/,"i'm at a loss with one of my high school math students.

she is SO impatient when it comes to math, she immediately gives up on any question she doesn't know and reverts to the answer key/chatgpt to cheat.

she has dropped out of her in-school math course in favour of online math (same curriculum) solely for the fact that she can use AI to cheat her way through the coursework. she has openly (and rather cockily) bragged about using chatgpt to do 20 PAGES of homework without learning a thing. i tried advising her this is not fair to herself/her classmates and that she's only failing herself, but she essentially laughed and told me i didn't have a good enough argument and that she doesn't care.

in all my years of tutoring, i've never gotten frustrated with a student, but i do feel offended and a bit disrespected. i have such a crazy schedule this term (no days off until december, woohoo!) and have had to turn down truly motivated students due to my prescheduled sessions with this student 2x/week. i feel like she's wasting my time when i could be helping people who want to put in more than 0 effort.

like what do i do? WIBTA if i told her how i feel she's wasting both our time? i almost want to contact her school and let them know everything she's told me about chatgpt, but i think i might be out of line. PLEASE ADVISE!!



this may or may not be relevant, but kind of need to rant...i'm having other issues with this student, including:

\- lying when i ask her if she understands something (says yes, then goes to do it wrong or not at all)

\- claiming the next question is ""easy and obvious, so we can skip it"", only to giggle and confess she has no idea when i press her to prove that she can do it 

\- i'm in the middle of showing her the step-by-step on how to solve a problem/showing her where she went wrong, she completely ignores me and frantically searches for an answer key (this has gotten so distracting i have to confiscate the answer keys while we work)

\- tells me she doesn't need me for help on homework because she has chatgpt, instead only wants help DURING ONLINE EXAMS (i shot that down immediately)

\- doesn't believe me when i tell her something is right or wrong; is only ever convinced by the answer key (e.g., does not believe that 10\*20 is different from 10\^20, despite explaining the concept in many ways...still frequently punches in \* on calculator despite physically writing a number as an exponent)

\- the only time she confidently approaches problems is when there is an almost identical replica in front of her to copy each step

  
i would've fired this client long ago, only her parents have prepaid me for another few hours. help me !!",active,10
1ga3rd5,5,2024-10-23,WIBTA if I snitched on a high school student for using ChatGPT to cheat?,u/swallowthedice,AITAH,https://www.reddit.com/r/AITAH/comments/1ga3rd5/wibta_if_i_snitched_on_a_high_school_student_for/,"I tutor math and science as a part-time job (\~20 hours per week) on top of 3 other jobs, and I have never had such grief with a student. 

I am at a total loss with ""Taylor"". She is SO impatient when it comes to math, she immediately gives up on any question she doesn't know and reverts to the answer key/ChatGPT to cheat her way through it.

Taylor has dropped out of her in-school math course in favour of online math (identical curriculum) solely for the fact that she can use AI to cheat her way through the coursework. She has openly (and rather cockily) bragged about using ChatGPT to do over a dozen pages of homework without learning a thing. Furthermore, after switching to online math, Taylor outright told me she doesn't need me for help on homework (because she has ChatGPT, of course!!), instead only wants help DURING ONLINE EXAMS (I shot that down immediately).

I tried advising her cheating is not moral or fair to herself/her classmates and that she's only failing herself, but Taylor essentially laughed and told me I didn't have a good enough argument to convince her and that she doesn't care anyways.

I've never once gotten frustrated while teaching a student, but I am offended and disrespected. I have such a crazy schedule and have had to turn down motivated students due to my prescheduled sessions with Taylor twice/week. I feel like she's wasting my time when I could be helping kids who want to put in more than 0 effort.

I am already very biased against AI, ChatGPT, and the like, so to hear one of my own students proudly use it makes me irrationally upset. 

WIBTA if I contact Taylor's school and let them know everything she's told me about cheating? Alternatively, WIBTA if I reprimanded her myself; telling her she's wasting her time, my time, and my other clients' time? 

Only problem is her parents have prepaid & scheduled me for 20 hours (only 7 more to go!) so I can't fire her as a client...as much as I want to.

TL;DR: My high school student brags to me (tutor) about using ChatGPT for homework/test answers and I want to rat her out to her school for academic misconduct.



This may or may not be relevant, but in case you're interested...I'm having other issues with Taylor, including:

* lying when I ask her if she understands something (says yes, then goes to do it wrong or not at all)
* claiming the next question is ""easy and obvious, so we can skip it"", only to giggle and confess she has no idea when I press her to prove that she can do it
* in the middle of showing her the step-by-step on how to solve a problem/showing her where she went wrong, she completely ignores me and frantically searches for an answer key (this has gotten so distracting I have to confiscate the answer keys while we work)
* doesn't believe me when I tell her something is right or wrong; is only ever convinced by the answer key
* the only time she confidently approaches problems is when there is an almost identical replica in front of her to copy each step",User_deleted,4
1gak3bw,7,2024-10-23,Student with a physical disability using ChatGPT ,u/Just_an_idea_gen,ChatGPT,https://www.reddit.com/r/ChatGPT/comments/1gak3bw/student_with_a_physical_disability_using_chatgpt/,"Iâ€™m going to college. I use an eye tracker on an iPad and I canâ€™t vocally speak or use of my limbs for anything. Before trying out ChatGPT, it takes me - not hours - but days just to complete one assignment. Itâ€™s exhausting. Most of the tasks require a lot of time are making annotations on my resources and actually preparing/writing the assignment or essay. 

I can see how ChatGPT can make things four times as efficient for me and I am not tempted to cheat. Iâ€™d get my degree and then Iâ€™d be fucked in the real world. My college obviously has a non-ChatGPT rule. However for students like me who without using ChatGPT as a tool, have to go through really fucked up barriers. The education system has always been fucked up that I am thinking of quitting and moving onto my alternative career path.

HOWEVER I want to see how to utilize ChatGPT for school. I want to know how to navigate around some of the ethical issues. For example, ChatGPT could give me ideas/insights that Iâ€™ve never thought before. How do I think about that? Another example would be that I am not permitted to utilize ChatGPT during an exam and I have to write an essay which would take hours. If I become reliant upon ChatGPT, then what would happen during an exam? 
",User_deleted,7
1gb9ruz,8,2024-10-24,Am I stupid or Machine learning course is too hard?,u/One_Bonus_8960,Indian_Academia,https://www.reddit.com/r/Indian_Academia/comments/1gb9ruz/am_i_stupid_or_machine_learning_course_is_too_hard/,"Warning: Extremely long post, \~1400 words.

I am from a tier 4 local college in India, qualifications: currently in 5th semester, B.Tech.

I do not think I am academically challenged, I personally think I did pretty well in engineering entrance exam and state board exam. Even though my rank was good enough to get into ""good"" private colleges in Bangalore, I decided to stay in my home and attend a ""supposedly"" good private college close to home.

Needless to say, the college isn't good. It's pretty bad to be honest. Now I'm in my third year of computer science and engineering degree and the amount of problems in this college is ridiculous. Anyway, that's besides the point.

One of the problems in Indian engineering educations, is, according to most people, ""outdated syllabus"". I don't think this is a big issue, the standard CSE curriculum consists of all basic foundations of computer science. I don't see any problem with teaching the basics. Basic foundations of the field cannot be updated. I don't think such a thing is possible. 

However my college tries to fix this ""outdated syllabus"" issue 3rd year onwards. We are taught Web technologies (react, spring boot etc.) and I have checked that we have a blockchain elective, there's more, but this comes at the expense of theory of computation course taught in other colleges. My college also fixes the outdated syllabus problem by updating the machine learning course.

That is fine and all, but I think I might be stupid because I simply do not understand our machine learning course.

I have seen that all computer science programs in our country do have a AI/ML course in 3rd year. But in my college, it seems like we ONLY have AI/ML courses for a comp sci program 3rd year onwards because there's too many mandatory courses on AI that I am forced into (I didn't sign up for this, the program got updated this year, just before I entered 3rd year).

The mandatory courses are ""Machine learning and deep learning"" in 5th semester and ""NLP with generative AI"" in 6th semester, I am aware only of these, but I'm pretty sure there's one more in 4th year.

I will get into the syllabus but let me talk about projects. We have mandatory project in the ML/DL course, a mini project (also in AI/ML but we have a choice, though about 70% choices are in AI/ML), a minor project (similar to mini project), and senior year project (most likely the same structure as minor project in 3rd year).

It's evident that there is too much emphasis on ML in this college.

But I have problems with this, please correct me, I think I am stupid, please free to criticize my thinking.

My problem is that there is TOO MANY WORDS, TOO MUCH technical jargon thrown around without really explaining why things work.

Let me outline the syllabus:

1. Introduction to AI/ML, linear regression, logistic regression, Bayesian classification, decision trees.

2. Regularization, support vector machines.

3. Ensemble learning, bagging, boosting.

4. Neural networks, introduction, convolutional neural networks.

5. Sequence to sequence models, attention mechanism, transformers.

I have omitted many more parts of the syllabus, if interested, I can share the whole course plan.

In the above syllabus, only chapter 1 and neural network introduction has mathematics, the rest of the syllabus is just prose after prose. I feel like the course is way too abstract for an engineering course. They use fancy words but never ever explained anything deeply. 

Now the thing is, I don't have any problems with abstraction. Operating system course was also abstract, but not THIS abstract. We had plenty of low level concepts already taught in digital design and computer organization course so operating system, though abstract, made complete sense. But this course has been taught with no background in mathematics and statistics. None of the concepts which are taught in maths courses are linked in this course. Most of the course is just fancy diagrams and technical vocabulary thrown around, which I cannot seem to understand one bit, because I believe I do not have the necessary prerequisites to even understand these concepts.

I would like to say that, I would just move on by memorizing the fancy words (which is what I believe our teachers are doing) and passing the course somehow. But the problem is projects.

Projects are a massive part of my CGPA. I had no knowledge of AI prior to signing up for a mini project in AI, and once I signed up, there is no going back. I have no choice but to make projects in ML/AI for mini, minor and senior projects, the system is like that (I will come back to this later).

Problem with projects is that these problem statements are just... way too high level. I have looked up online, and it seems like most of these projects require at least a PhD to understand. I was required to do a literature survey on my problem statement (all on my own), but I did not understand A SINGLE WORD from whatever research papers I found. I somehow just memorized the key words and passed the review (thanks to ChatGPT), I had to present a power-point presentation with 5 research papers.

Some technologies (?) on which projects are made include: 

\- Generative Adversarial networks, 

\- Explainable AI, 

\- NN architecture search, 

\- Vision Transformers, 

\- Optimization, 

\- Proving the existence of a computer that can solve halting problem, 

\- Bringing back dead people 

(last two are obviously sarcasm, but I can make projects on the latter 2 as well as I can make on the others. Some problem statement are in an Alien language, I can tell you more about it if you want).

I just don't know why no other student seems to have any problems with this. This is just my personal opinion but I don't think knowing technical jargon is equivalent to understanding the concept. I don't say I understand something until I understand it as well as I can understand for example, elementary calculus, and I am pretty confident on my understanding of elementary calculus that I studied in class 12.

All other students just find some ready made project on GitHub and copy paste the research papers and use Humanize AI to somehow bring down the plagiarism rate.

I don't like doing projects like this one bit. I feel trapped because I cannot switch my problem statement. It also doesn't help that the professor coordinating mini, minor and the machine learning course is a big bully who threatens to fail me if I even think if changing my problem statement now. He's a bully in general, he has made it clear that whoever doesn't publish papers for mini and minor project (and cite his research and give him authorship) will not be eligible to pass the course. And he seems to mean it.

I also have to mention that, the course's lecture classes were finished in 7 days, with some 2.5 hours of lectures a day, a week before the semester officially began. Yes, entire syllabus I mentioned above was taught in 7 days, with 2.5 hours of continuous lectures every day. And now I am expected to make two projects in ML/DL and write papers about them.

I don't know what to do now. AI is getting shoved down my throat. I don't like making projects by plagiarizing others' work. I think I will like ML/AI if I learnt it slowly at my own pace, but it will probably take years until I begin understanding these research papers, let alone come up with a novelty.

Please help me, maybe I am completely wrong and all this is completely normal. But I don't see the same issue being raised by my friends in other colleges. It might be possible that my friends too don't care about the project and are like others in my college. I want to learn stuff deeply and not just at an abstract high level. That kind of learning feels so superficial and shallow. I understand that many people in computer science feel that there is no need to reinvent the wheel, but how can I make a car without ever understand how the wheels work, in as much detail as possible?

I would love to hear your thoughts. Thank you for your time. I know this post was too long. ",User_deleted,9
1gb9yjd,2,2024-10-24,Am I stupid or Machine learning course is trash in my college?,u/One_Bonus_8960,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/1gb9yjd/am_i_stupid_or_machine_learning_course_is_trash/,"Warning: Extremely long post, \~1400 words.

I am from a tier 4 local college in India, qualifications: currently in 5th semester, B.Tech.

I do not think I am academically challenged, I personally think I did pretty well in engineering entrance exam and state board exam. Even though my rank was good enough to get into ""good"" private colleges in Bangalore, I decided to stay in my home and attend a ""supposedly"" good private college close to home.

Needless to say, the college isn't good. It's pretty bad to be honest. Now I'm in my third year of computer science and engineering degree and the amount of problems in this college is ridiculous. Anyway, that's besides the point.

One of the problems in Indian engineering educations, is, according to most people, ""outdated syllabus"". I don't think this is a big issue, the standard CSE curriculum consists of all basic foundations of computer science. I don't see any problem with teaching the basics. Basic foundations of the field cannot be updated. I don't think such a thing is possible.

However my college tries to fix this ""outdated syllabus"" issue 3rd year onwards. We are taught Web technologies (react, spring boot etc.) and I have checked that we have a blockchain elective, there's more, but this comes at the expense of theory of computation course taught in other colleges. My college also fixes the outdated syllabus problem by updating the machine learning course.

That is fine and all, but I think I might be stupid because I simply do not understand our machine learning course.

I have seen that all computer science programs in our country do have a AI/ML course in 3rd year. But in my college, it seems like we ONLY have AI/ML courses for a comp sci program 3rd year onwards because there's too many mandatory courses on AI that I am forced into (I didn't sign up for this, the program got updated this year, just before I entered 3rd year).

The mandatory courses are ""Machine learning and deep learning"" in 5th semester and ""NLP with generative AI"" in 6th semester, I am aware only of these, but I'm pretty sure there's one more in 4th year.

I will get into the syllabus but let me talk about projects. We have mandatory project in the ML/DL course, a mini project (also in AI/ML but we have a choice, though about 70% choices are in AI/ML), a minor project (similar to mini project), and senior year project (most likely the same structure as minor project in 3rd year).

It's evident that there is too much emphasis on ML in this college.

But I have problems with this, please correct me, I think I am stupid, please free to criticize my thinking.

My problem is that there is TOO MANY WORDS, TOO MUCH technical jargon thrown around without really explaining why things work.

Let me outline the syllabus:

1. Introduction to AI/ML, linear regression, logistic regression, Bayesian classification, decision trees.
2. Regularization, support vector machines.
3. Ensemble learning, bagging, boosting.
4. Neural networks, introduction, convolutional neural networks.
5. Sequence to sequence models, attention mechanism, transformers.

I have omitted many more parts of the syllabus, if interested, I can share the whole course plan.

In the above syllabus, only chapter 1 and neural network introduction has mathematics, the rest of the syllabus is just prose after prose. I feel like the course is way too abstract for an engineering course. They use fancy words but never ever explained anything deeply.

Now the thing is, I don't have any problems with abstraction. Operating system course was also abstract, but not THIS abstract. We had plenty of low level concepts already taught in digital design and computer organization course so operating system, though abstract, made complete sense. But this course has been taught with no background in mathematics and statistics. None of the concepts which are taught in maths courses are linked in this course. Most of the course is just fancy diagrams and technical vocabulary thrown around, which I cannot seem to understand one bit, because I believe I do not have the necessary prerequisites to even understand these concepts.

I would like to say that, I would just move on by memorizing the fancy words (which is what I believe our teachers are doing) and passing the course somehow. But the problem is projects.

Projects are a massive part of my CGPA. I had no knowledge of AI prior to signing up for a mini project in AI, and once I signed up, there is no going back. I have no choice but to make projects in ML/AI for mini, minor and senior projects, the system is like that (I will come back to this later).

Problem with projects is that these problem statements are just... way too high level. I have looked up online, and it seems like most of these projects require at least a PhD to understand. I was required to do a literature survey on my problem statement (all on my own), but I did not understand A SINGLE WORD from whatever research papers I found. I somehow just memorized the key words and passed the review (thanks to ChatGPT), I had to present a power-point presentation with 5 research papers.

Some technologies (?) on which projects are made include:

\- Generative Adversarial networks,

\- Explainable AI,

\- NN architecture search,

\- Vision Transformers,

\- Optimization,

\- Proving the existence of a computer that can solve halting problem,

\- Bringing back dead people

(last two are obviously sarcasm, but I can make projects on the latter 2 as well as I can make on the others. Some problem statement are in an Alien language, I can tell you more about it if you want).

I just don't know why no other student seems to have any problems with this. This is just my personal opinion but I don't think knowing technical jargon is equivalent to understanding the concept. I don't say I understand something until I understand it as well as I can understand for example, elementary calculus, and I am pretty confident on my understanding of elementary calculus that I studied in class 12.

All other students just find some ready made project on GitHub and copy paste the research papers and use Humanize AI to somehow bring down the plagiarism rate.

I don't like doing projects like this one bit. I feel trapped because I cannot switch my problem statement. It also doesn't help that the professor coordinating mini, minor and the machine learning course is a big bully who threatens to fail me if I even think if changing my problem statement now. He's a bully in general, he has made it clear that whoever doesn't publish papers for mini and minor project (and cite his research and give him authorship) will not be eligible to pass the course. And he seems to mean it.

I also have to mention that, the course's lecture classes were finished in 7 days, with some 2.5 hours of lectures a day, a week before the semester officially began. Yes, entire syllabus I mentioned above was taught in 7 days, with 2.5 hours of continuous lectures every day. And now I am expected to make two projects in ML/DL and write papers about them.

I don't know what to do now. AI is getting shoved down my throat. I don't like making projects by plagiarizing others' work. I think I will like ML/AI if I learnt it slowly at my own pace, but it will probably take years until I begin understanding these research papers, let alone come up with a novelty.

Please help me, maybe I am completely wrong and all this is completely normal. But I don't see the same issue being raised by my friends in other colleges. It might be possible that my friends too don't care about the project and are like others in my college. I want to learn stuff deeply and not just at an abstract high level. That kind of learning feels so superficial and shallow. I understand that many people in computer science feel that there is no need to reinvent the wheel, but how can I make a car without ever understand how the wheels work, in as much detail as possible?

I would love to hear your thoughts. Thank you for your time. I know this post was too long.",User_deleted,0
1gcmop3,11,2024-10-26,AI detectors and worry before/after submitting an essay,u/Lanky_Trip_1923,UniUK,https://www.reddit.com/r/UniUK/comments/1gcmop3/ai_detectors_and_worry_beforeafter_submitting_an/,"so our uni has been cracking down on AI use which is making me extra paranoid when iâ€™m submitting my essay knowing that they will use AI detectors.

i have read and read uniâ€™s AI policy and i 100% abide by it. i donâ€™t use ChatGPT as its generally unreliable but i do use Grammarly to touch up on grammar (i ignore their clarity suggestions and donâ€™t use their genAI function) and i use Elicit AI to search for papers (this has been specifically recommended and permitted by our uni).

anyway, i write all my essays myself and never copy and paste anything. however, after some students have been caught using AI on our course which lead to academic misconduct, i have been running my essays passed online AI detectors. whilst most of it deemed my essay as human content (which it should be as it was), some have highlighted certain parts of my essay as AI-generated when it is my own words and work. this is particularly when there is a part that involve a lot of research references.

this generates a lot of paranoia and emotional turmoil that my work can be incorrectly taken as AI by AI detectors and i could be falsely accused of academic misconduct. it means im constantly rewording my work before submission but even then AI detectors still highlight parts of my work as AI generated. 

i have recently took 2 years out of uni and AI have bursted onto the scene during this time so i never dealt with this problem before. i know i should have nothing to worry about as i used AI responsibly as per my uniâ€™s guidance but it is worrisome that maybe my writing style is triggering AI detectors to detect it as AI and the vague accuracy of these detectors can put my academic integrity into jeopardy.

this is causing significant worries before submission and waiting for the coursework to be marked. 

i have started using google docs to write my essays so i have the whole version history to back me up should i be called up to the meeting regarding any academic misconduct concerns. i think our uni use a VIVA style interview with the module leader to assess learning outcomes if thereâ€™s suspect use of genAI but it is so stressful even just thinking they may be a chance that i will need to defend myself.

does anyone else feel the same about these new AI detection function on Turnitin that uni uses and it is just causing a whole lot of unnecessary stress?",User_deleted,10
1gdq7np,1,2024-10-27,"privileged yet stupid, and a failure ",u/No-Conference-1108,venting,https://www.reddit.com/r/venting/comments/1gdq7np/privileged_yet_stupid_and_a_failure/,"Honestly, everything has been boiling up until this point.

Iâ€™m not cool, Iâ€™m not pretty, Iâ€™m fat and ugly, and I have a horrible temper. I have a horrible tendency to lie, whether it's about big stuff or white lies about anything, and I hate myself. I canâ€™t talk to boys without wanting to throw up and die, but I also can't make friends. In social group settings, Iâ€™m awkward, and I am not funny, and people NOTICE. They think I don't like them, which isn't true, but Iâ€™m always just so preoccupied and unfunny. And Iâ€™m constantly thinking about how horrible I am. I have bad health problems too, but like mini ones, so I am always getting infections, acne, hair falling out, bad teeth, bad vision, ugly fingernails, wrinkles, etc. So basically nothing about me is good, and honestly, I just want to die. Like, what is the point of living when there isn't a SINGLE good quality about me? Iâ€™m a germaphobic b\*tchy freak, and my mom genuinely hates me because of how big of a failure I am. I have failed every single math test since the beginning of this year and got straight Cs last year, which was my junior year, the most important year ever for colleges. Now I haven't been doing any work because, first of all, what the hell is the point? What's worse is that my sister is better than me in every aspect, and every time she comes home, my whole family is like, â€œ\[her name\], yay! Youâ€™re home! I haven't seen you in so longâ€ (this is maybe if they missed seeing her yesterday). And like, I get it because I miss her too even when she's gone, and no one misses me. I was gonna say ""no one SEEMS to miss me,"" but it's genuinely true how nobody misses me. My mom treats me like I'm 12, but Iâ€™m notâ€”Iâ€™m 17 and have no responsibility. She doesn't teach me how to do anything, and I donâ€™t know if itâ€™s because she hates spending time with me or thinks I'm so incompetent (which I am). She would rather just do it herself or have someone else do it. So Iâ€™m incompetent, but I donâ€™t know how to do anything. I genuinely donâ€™t know how to do anything. She tells me to give up on education, and Iâ€™m Chinese, so honestly, education is THE MOST important thing to someoneâ€™s child, and being a good student is the best trait anyone could possibly have. I have no competitive drive, and I am not even beautiful, which is, unfortunately, one of the most important things a woman needs: beauty, to marry rich and become a housewife. But Iâ€™m neither. I donâ€™t even have qualities to be a housewife. Like I said, I canâ€™t do basic household things because my mom 1) wonâ€™t let me, 2) I donâ€™t know how, 3) I was never taught. I am not smart and definitely wonâ€™t make any money in the future. It sucks because all my friends are talking about going to top colleges, and Iâ€™m happy for them because their futures are so bright. They worked so hard in high school, achieving 4.0+ GPAs despite having extremely horrible home situations and financial struggles, while my family is upper middle class and I have tutors, etc. I'm also constantly being invalidated because I am upper-middle class, am the youngest, etc. and I know I can't blame others and my situation for being incompetent because naturally this way, I should be in the best spot to become a successful, well-rounded individual. Why was I born this way? Why can't I just have the natural drive and competency to have a successful future?

Iâ€™ve been thinking about offing myself ever since I was 10, and it has shown because I genuinely donâ€™t have the drive or anything to do anything. The only time I actually tried was freshman year, but after that, I got a C in my first-semester chemistry class. Since then, it just spiraled from being an A student to an F student. I don't do any work unless it's classwork they force us to do in class, and once I go home, I just doomscroll on TikTok to forget about everything. I know Reddit isn't a nice platform where the communities are supportive, so honestly, Iâ€™m not expecting a positive response. I'm so freaking lazy and unmotivated that I even used ChatGPT to make this post grammatically correct. What's the point of anything?? ask me anything ! ",User_deleted,1
1gf28ah,10,2024-10-29,How do you feel about newer generations and their relationship with technology? ,u/menamongleruins,AskTeachers,https://www.reddit.com/r/AskTeachers/comments/1gf28ah/how_do_you_feel_about_newer_generations_and_their/,"Iâ€™m sure this gets asked a lot but Iâ€™m just curious. Iâ€™m an undergrad in college. I did 3 semesters right after I graduated high school in 2016, but took a few years off to work and establish myself. Iâ€™ve now returned and things feelâ€¦different. Students donâ€™t seem to engage in Class at all. Everyone has laptops and isnâ€™t paying attention, browsing other sites. Nobody can stay focused. The lights are just completely off and when they get called on, itâ€™s clear they werenâ€™t tuned in at all. The professors are all either frustrated or demoralized by this. Iâ€™m also in several WhatsApp groups for my classes and every student is complaining about the professor, about grades and due dates, and asking how they can use ChatGPT to do their work for them. This is so astonishing to me because itâ€™s different than the class environment I had in 2016/17. 

Iâ€™ve also noticed standards are just gone. Every exam, test, or essay must be supplemented by a curve or every student fails. It feels unfair when I spend weeks studying and consuming the material. 

I know I sound like an old man hating on younger generations already. Iâ€™m okay with that. Iâ€™m more so confused by what appears to be such a rapid shift. Are you teachers watching this happen in real time? Have you noticed this too? ",active,8
1gf7lvh,1,2024-10-29,"I need help in my project which has something to do with Translating Screen Coordinates [ x, y ] to Camera Pan and Tilt angles.",u/Natural_Cry7493,learnmachinelearning,https://www.reddit.com/r/learnmachinelearning/comments/1gf7lvh/i_need_help_in_my_project_which_has_something_to/,"Why I'm Seeking Help:

Iâ€™m a diploma (a 3-year course taken after matriculation) student and now has a final semester project to complete. In our course, we mostly learn the basics and fundamentals, so Iâ€™m struggling to make this project on my own. For the past three months, Iâ€™ve been trying to put it together by researching resources on the internet and using ChatGPT, but I havenâ€™t been successful. Now, with only a month left before the presentation and submission, Iâ€™m feeling really stressed and desperate for help. Please see the project details below. ðŸ‘‡

I have an ESP32-CAM mounted on a 2-axis servo arm that can pan and tilt. I want to stream the live feed to a browser or app, allowing the user to click a point on the screen, causing the camera to pan and tilt so that the selected point becomes the center of the view.

Additionally, I plan to attach a water hose connected to a water pump, operated by a servo linked to the ESP32. The goal is for the pump to spray water on plants that I tap on the screen (as seen through the camera). After identifying and tapping on each plant, I want to store these coordinates as plant1, plant2, etc., so I can water them later. Each plant would receive a specified amount of water, based on a set time period for the pump (which operates at 1L/min) with the device converting the water volume (in liters) to seconds.

I want to build a web interface that:

â€¢Displays the live camera feed with joystick controls for panning and tilting.

â€¢Shows the coordinates of each marked plant.

â€¢Prompts the user to specify the amount of water (in liters) for each plant, which the device will convert into seconds.

Please provide the code and procedure for setting up the ESP32 and the website.

",User_deleted,0
1gfxj1v,2,2024-10-30,Do NOT take Computer Science. Period.,u/inherentlil,JEENEETards,https://www.reddit.com/r/JEENEETards/comments/1gfxj1v/do_not_take_computer_science_period/,"Main points: Do not look forward to Software Engineering jobs the same way anymore. Jobs going down day by day, and it's evident in placements in colleges all across India. Even if the market gets better, so will AI - and jobs will only reduce. Also, as a side point, please do not join IIIT Delhi.

I'm posting here because I want you to know BEFORE you join college. Not after.

I'm currently a 3rd year student at IIIT Delhi. My college was supposed to have ~fancy~ placements. I have DTU / NSUT / IIT Delhi friends near me. Let me tell you, placements are a shit show everywhere.

My friend sitting in CS @ DTU tells me that he's expecting 7-10 LPA despite being very smart (my personal opinion) and having done over 700 LC questions.

It's October. Placements started in August. 3 months gone, only ~100 students have been placed in my college. Other than that, around 70 pre-placement offers. So 170 offers in total. Total batch size? 600+. Also, only around ~100 people got internship this year. Out of 600.

Last year, only around ~400 people got placed by the end of placement season. Around 150 people remained unplaced. Any other statistic that you see from my college has been heavily manipulated.

Do you know what's worst? The fact that I'm spending all my time learning to build things that somebody with ChatGPT can build with half the knowledge as me. And most of these are ignorant people - not even trying to learn, just prompt engineering throwing everything at GPT.

Everyone is using GPT for assignments. People are cheating in company tests, interviews, competitive programming contests, LeetCode contests, everywhere. It's a shit show. Why am I even learning so hard to code? It feels purposeless.

Tech is not worth anymore. If you still have a choice, choose something else.",User_deleted,2
1ggh5d2,29,2024-10-31,They just can't help themselves (AI made me do it),u/LetsGototheRiver151,Professors,https://www.reddit.com/r/Professors/comments/1ggh5d2/they_just_cant_help_themselves_ai_made_me_do_it/,"Started a new term last week. Several egregious examples of AI discussion posts. I sent them into the Academic Integrity Office as instructed. First time offenders, so a "" teachable moment."" One student resubmitted with a paragraph-long email (probably ChatGPT assisted) explaining that they understood the penalties of using AI blah blah. Literally under 24 hours later they posted the Week 2 discussion which is also obviously and blatantly ChatGPT. ðŸ¤¦ðŸ»â€â™€ï¸",active,32
1ggl53d,23,2024-10-31,my biochem professor is the worst. ,u/Square_Bet_4239,CollegeRant,https://www.reddit.com/r/CollegeRant/comments/1ggl53d/my_biochem_professor_is_the_worst/,"I have been feeling very angry, so I just wanted to come on here to let it all out. I am a pharmacy student who recently just started my first semester of pharmacy school recently. Who knew that during the first week of classes, my biochem professor would quit? So instead of my school finding a capable professor to teach, they decided to just call a random professor to teach biochem. Not only was it a random professor, but it also had to be my orgo professor. I hated that professor I dropped that class as soon as I could. He doesn't know what he's doing, whenever someone asks him what's going to be on the exam he just laughs and says ""everything that's taught in class"". When we ask him for an outline he also just laughs. He's like I'm not giving you guys shit. Throughout the semester we would ask him what chapters are on the quiz but the thing is he doesn't even know what chapter he's teaching. He would just say I don't know. Like what do you mean you don't know, you are the one that's writing the quiz so you must know what chapters, but no he just laughs. Like, give us a fucking answer. A few days ago we had our midterm and I got my grade back and I failed. Like how did I fail? He said that as long as you read your notes and look at his sample questions you should be fine. Come exam day, the exam looks like it's from ChatGPT. He basically just asked ChatGPT ""Give me questions that are as confusing and difficult as possible and don't bother with making it about bicohem, what about making it about orgo instead?"" None of the sample questions were on the exam and there were topics that we never even learned before. He also said that he recycles his quiz questions, but no he doesn't. The exam looked like it was for the wrong class. Only 20% of the people in my class passed and there are 152 students in my class. He came to class today and wrote on the board and it said that he ""curved"". By curved he just took out 2 questions. The exam is out of 50 btw. That curve didn't do shit, like wow I went from an F to an F. As a class, we tried to ask him about extra credit but he would just laugh it off and I'm just like what's so funny? This is a professional program, if I fail one class I'm basically on my way out of pharmacy school. It's like you'll still have a job, but I won't have a future because of you and all you do is laugh. No sympathy from this guy whatsoever.  We all as a class have already started talking to the Dean and she said she'll figure something out for us, but what the fuck is my professor's problem. Stop laughing every time we ask a serious question and do your job as a professor and teach us things that will actually be on the exam. We don't want you to constantly avoid our questions. We need to know what's going to be on our exams and not have every answer be ""I don't know"" because you should know it's your fucking exam that we are being tested on. Also is it that hard to make slides? Your messy ass handwriting combined with your accent also isn't doing it for this class. Also, I tried YouTube and reading textbooks, but they just don't align with what he teaches in class. I honestly won't even be surprised if he's been teaching us orgo all this time. 

  
TLDR: My professor is a terrible person who doesn't care enough about his students to let them know what is on the exams and things that he teaches don't line up with the sample questions that he gives us. ",active,25
1ggoaau,2,2024-10-31,Feel so lost at the moment,u/Comfortable_Movie189,csMajors,https://www.reddit.com/r/csMajors/comments/1ggoaau/feel_so_lost_at_the_moment/,"
Hi everyone,
Iâ€™m not really sure who talk to about this, so I thought why not come to Reddit lol. Iâ€™m in my 3rd year as a CS Major and I genuinely feel the most confused and lost Iâ€™ve ever been in my whole entire life. That is due to the fact that Iâ€™m rapidly losing interest and overall passion in CS. When I first started my cs major I was actually having a good time. I had a great calc 2 professor and learned so much from him, it was genuinely really fun going to school everyday and learning things from him. I also had a good intro to programming professor which made coding fun for me (it was the basics though). Now fast forward to now, Iâ€™m taking upper division classes and my entire world feels like it got turned 180. Never used chatGPT before but now I feel like I always have to use it or Google things to look stuff up and copy/paste the code because the coding assignments are too complex for me to figure out. I feel so guilty and unworthy knowing that I have to do this to pass a class. Itâ€™s so demoralizing. They donâ€™t really teach coding anymore, a lot of my professors have the â€œgo figure it out yourselfâ€ mentality, which is fine since I know many other universities do this aswell but I just donâ€™t think I learn well off that. 

Iâ€™m always a person who loves a same old routine. So being a CS major and always having to think outside the box or figuring out different ways to solve complex problems, I just donâ€™t think itâ€™s for me anymore.  But what do I do? Iâ€™m too deep in to fully switch out this major + telling foreign parents that I gave up software engineering isnâ€™t really the best idea. Plus scrolling through tiktok and Reddit, all I see are these amazing projects people have done while Iâ€™m here being a below average cs student. Itâ€™s also just been affecting my overall mental health feeling this lost in life. I can probably type all night about this but my phone is dying so Iâ€™ll end it here. Any advice or just overall thoughts would be nice. Please donâ€™t roast me too much my mental is already down lol.",User_deleted,2
