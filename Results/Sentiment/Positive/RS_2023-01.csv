10c2dfj,2,2023-01-14,Mitigating the Use of Chatbots in Academics and the Ethical Repercussions Thereof,u/sharxbyte,ArtificialInteligence,https://www.reddit.com/r/ArtificialInteligence/comments/10c2dfj/mitigating_the_use_of_chatbots_in_academics_and/,"
Been saving this for my cake day :) Hope you enjoy!


By ChatGPT and (u/sharxbyte)

As AI chatbots become more advanced, they may be used in a variety of academic settings to assist with tasks such as grading assignments and providing feedback to students. While chatbots can be a useful tool for instructors, it is important to consider both the potential benefits and drawbacks of using them in the classroom.

One potential benefit of chatbots is their ability to grade assignments quickly and accurately. This can save instructors time and allow them to focus on other tasks, such as providing personalized feedback to students. Chatbots may also be able to provide consistent and unbiased evaluations of student work, which can be especially useful in large classes.


There are also potential drawbacks to using chatbots in the classroom. For example, relying too heavily on chatbots may discourage critical thinking and creativity, as students may simply try to find ways to game the system rather than engaging with the material on a deeper level. Chatbots may also be unable to provide the same level of personalized feedback as a human instructor, which can be particularly important for students who are struggling or have specific questions.

Given these potential benefits and drawbacks, it is important for instructors to consider carefully how they will use chatbots in their classrooms. Here are a few strategies that instructors can use to mitigate the negative effects of chatbots while still taking advantage of their potential benefits:

Clearly communicate the role of chatbots in the classroom. Students should understand when and how chatbots will be used, and how their work will be evaluated. This can help to prevent misunderstandings and ensure that students are aware of the limitations of chatbots.

Incorporate activities that are difficult for chatbots to perform. For example, instructors might assign projects that require students to engage in creative problem-solving or work in groups. This can help to encourage critical thinking and creativity, and may also be more engaging for students.

Encourage students to use chatbots as a starting point, rather than relying on them completely. For example, students might use chatbots to check their work for errors, but should not rely on them to do the entire assignment. This can help to ensure that students are still putting in the effort to understand the material and are not simply trying to find ways to game the system.


In addition to these strategies, it is also important for instructors to consider how to prevent students from incorrectly conflating potentially sensitive topics, for example racism or immigration with topics that are completely unethical.

 Here are a few strategies that instructors can use:

 Before students begin working on assignments that may involve sensitive topics, it is important for instructors to clearly communicate their expectations and guidelines. This can include outlining the appropriate way to approach and discuss sensitive topics, as well as outlining any rules or consequences for inappropriate behavior.

 Encourage students to engage in respectful dialogue when discussing sensitive topics. This can include actively listening to others, being open to hearing different viewpoints, and avoiding language or behavior that is dismissive, disrespectful, or inflammatory.

Make sure students have access to resources and support if they feel overwhelmed or triggered by discussions about sensitive topics. This might include providing a list of counseling services or other resources for students to use as needed.

If a discussion about a sensitive topic becomes inappropriate or unethical, it is important for instructors to intervene and take steps to redirect the conversation. This might include reminding students of the guidelines for respectful dialogue, or providing additional resources or support if necessary.

By following the strategies outlined above, university instructors can mitigate the negative effects of chatbots in the classroom while still taking advantage of their potential benefits. Additionally, instructors can help to create a safe and respectful environment for discussions about sensitive topics, and can help to prevent students from conflating these topics with ones that are completely unethical. By carefully considering the use of chatbots and promoting respectful and ethical behavior, instructors can help to ensure that students are able to learn and grow in a positive and supportive environment.

-(OpenAI, 2020-2023) ""ChatGPT: A Variant of GPT-3 for Chat Applications.

https://chat.openai.com/chat

prompt: Please help me write an article explaining how university instructors can mitigate the use of AI chatbots in the work of students
~
Can you write the article for me?
~
And how do we stop students from incorrectly conflating sensitive topics about race or immigration with topics that are completely unethical?",active,2
10gkmcj,0,2023-01-19,ChatGPT in Education,u/jordanradke,Teachers,https://www.reddit.com/r/Teachers/comments/10gkmcj/chatgpt_in_education/,"If you haven’t yet heard of or haven’t yet checked out ChatGPT, you should.  It is a pretty incredible piece of artificial intelligence technology. The ramifications for widespread access to AI are going to be astonishing across all sectors, education included. 

To my fellow educators, I gave it the following prompt: 

“Write a step by step guide for what public school teachers need to do to ensure they are not replaced by artificial intelligence. “

Here is the fascinating response written by that very same Artificial Intelligence:

“1. Stay up to date: It’s important to stay up to date with the latest AI, machine learning and automation trends, so that the teacher has a good understanding of the potential applications of these new technologies in the classroom. 

2. Leverage technology: Incorporate technology into lesson plans and activities to get better engagement from students and check for understanding. If done correctly, this will show that teachers still bring value to the classroom.

3. Demonstrate adaptability: Show how you can easily adapt to new digital tools, technology, and trends. Artificial intelligence technologies are constantly improving, so the ability to quickly learn and understand these systems enables teachers to offer insights and new ideas.

4. Emphasize interpersonal skills: While digital tools, technology, and AI can help with instruction, there’s still a need for traditional teaching skills and rapport building with students. AI cannot replace years of experience and relationship building with your students; instead…”

What do you think?",active,0
10izri5,15,2023-01-22,ChatGPT passed a Wharton MBA exam and it’s still in its infancy. One professor is sounding the alarm,u/CSCareerAnswer,AskProfessors,https://www.reddit.com/r/AskProfessors/comments/10izri5/chatgpt_passed_a_wharton_mba_exam_and_its_still/,"https://fortune.com/2023/01/21/chatgpt-passed-wharton-mba-exam-one-professor-is-sounding-alarm-artificial-intelligence/


I think we can confidently say, the end higher education oligarchs will come sooner than later.


Do you have any backup plans? Im a part time lecturer at a community college (in additon to my full time software job) and ive been encouraging students to use chatgpt as a resource as I do in the real world, and their grades have significantly improved. Much better code coming in from students, etc..

Ive created automated systems for grading and even have a system setup to send me the ones where the results seem off (as in the ai made a mistake)",User_deleted,16
10lx9wl,1,2023-01-26,I feel like I'm in some sort of arms race with OpenAI to outwit their dumbing-down of chatGPT.,u/ChadRickTheSane,ChatGPT,https://www.reddit.com/r/ChatGPT/comments/10lx9wl/i_feel_like_im_in_some_sort_of_arms_race_with/,"I've been learning how to use the API, but chatGPT is still so much more intuitive, despite the restrictions. I've been experimenting with prompts to prevent it from spouting mindless drivel and am having some success, this was generated from a single prompt in a new chat window: 

&gt; When it comes to how we treat others, there is a core principle that guides our actions: we must be able to justify our actions to the people we are interacting with. This principle underlies all forms of human relationships, from our closest friends and family to strangers we pass on the street.

&gt;But what does it really mean to ""justify"" our actions? It means that we must be able to explain our actions in a way that makes sense to the other person and that they can't reasonably reject. We must strive to find common ground and understanding, rather than just imposing our own beliefs and values on others.

&gt;This principle is not something that can be set in stone. It's not a rulebook that we can follow, but rather a continuous process of working out the terms of moral justification. It's a task that never truly ends, as people's beliefs and values change over time and what was once considered justifiable may not be so in the future.

&gt;In our daily lives, this principle may manifest in small ways - being honest with our friends, being respectful of our coworkers, and treating everyone we encounter with kindness and empathy. But it also extends to larger societal issues, such as how we treat marginalized communities and how we address systemic injustices.

&gt;It's easy to get caught up in our own perspectives and beliefs, but it's important to remember that treating others with respect and empathy is a continuous process. It requires us to listen, to learn, and to strive to find common ground. It may not always be easy, but it is essential to building strong, healthy relationships with those around us.

This could have easily been written by an undergraduate student as a paper or someone looking to give a speech to a group. I'm finding it's possible to get good results but it takes more nuance and careful prompting to prevent the dreaded ""as a language model..."" or ""I'm sorry Dave, I can't do that...""

Why does everything nice and useful that comes along have to get lobotomized? 

I'm curious how others are developing their prompting process. I'm generally starting off with an overview [Here's what I want] then instructions on what not to do [avoid common tropes...do not mention that you are a language model, instead write as if you were a... do not impose any other moral framework...] then a seed example, if available like a quote on the topic or direction on how I want the response presented [write this at a collegiate level] or [write this in the style of an 18th century lawyer]. 

How are you getting the responses you are looking for out of the newest chatGPT model?",active,1
10pm4oi,21,2023-01-30,GPT3 has revolutionised my workflow,u/ThoughtsAndTorts,GPT3,https://www.reddit.com/r/GPT3/comments/10pm4oi/gpt3_has_revolutionised_my_workflow/,"I am an entry level data analyst and having ChatGPT to ask questions to has been unbelievably helpful in terms of learning. It is like having an experienced pro there to assist me when I need suggestions on a new approach, what function might work best to solve a problem, or any other random questions I might have.

I feel pretty confident saying I will incorporate GPT3 or similar alternatives into any learning process I have going into the future. 

Have any other students/workers found GPT3 helpful? Either in your professional or personal life?",User_deleted,19
10q6dh9,4,2023-01-31,Public Perception of AI,u/berekin556,ChatGPT,https://www.reddit.com/r/ChatGPT/comments/10q6dh9/public_perception_of_ai/,"I began using ChatGPT pretty much immediately after it it came out (used Playground before that) and so it’s been quite interesting for me to see the general public’s reaction to it and the concept of AI in general unfold. I have some thoughts and points I’d like to discuss.

At first, I was pleasantly surprised because I was expecting a lot more push back and fear-mongering because of the general perception of AI in pop culture - but most people seemed to find it pretty cool. However recently - I’ve noticed a few things as it’s gained popularity and media coverage.

First off, in academia, a lot of schools just seem to view it as a method of cheating for students rather than the educational tool I personally believe it easily could be. I’ve seen quite a few institutions just outright ban it which just seems like a woefully short-sighted path to take to me.

Second - I’ve noticed a decent amount of misinformation and false narratives forming around the bot and can only foresee it getting much worse. This [thread](https://www.reddit.com/r/walkaway/comments/10q0ovt/chatgpt_refuses_to_create_a_poem_admiring_donald/?utm_source=share&amp;utm_medium=ios_app&amp;utm_name=iossmf) I came across would be a good example. It’s all the fear mongering, misinformed takes, and push-back I expected when it first came out. 

So, I guess my questions are: How do you see the public perception of AI evolving as it gets more popular? Do you see it slowly being largely embraced as a valid tool or will insititutions continue to shun it? Could it potentially become a point of political contention? I can easily see dinosaurs in governments just rejecting it outright. Would love to hear thoughts on this.

Edit: as a user pointed out, it is an alt right sub and not representative of the general public but I think it’s still interesting to look at as an example of where the perception of AI in the political realm could go (propaganda, fake news etc)",User_deleted,5
